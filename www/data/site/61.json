[
    {
        "url": "http://cs.stanford.edu/content/dtools",
        "text": [
            "d",
            "tools",
            "what",
            "kind",
            "of",
            "tools",
            "would",
            "you",
            "need",
            "to",
            "make",
            "a",
            "functional",
            "interactive",
            "prototype",
            "of",
            "a",
            "media",
            "player",
            "in",
            "minutes",
            "d",
            "tools",
            "is",
            "a",
            "hardware",
            "and",
            "software",
            "system",
            "that",
            "enables",
            "designers",
            "to",
            "rapidly",
            "prototype",
            "the",
            "bits",
            "the",
            "form",
            "and",
            "the",
            "atoms",
            "the",
            "interaction",
            "model",
            "of",
            "physical",
            "user",
            "interfaces",
            "in",
            "concert",
            "d",
            "tools",
            "was",
            "built",
            "to",
            "support",
            "design",
            "thinking",
            "rather",
            "than",
            "implementation",
            "tinkering",
            "with",
            "d",
            "tools",
            "designers",
            "place",
            "physical",
            "controllers",
            "e",
            "g",
            "buttons",
            "sliders",
            "sensors",
            "e",
            "g",
            "accelerometers",
            "and",
            "output",
            "dev"
        ],
        "content": "d.tools.  What kind of tools would you need to make a functional interactive prototype of a media player in 30 minutes? d.tools is a hardware and software system that enables designers to rapidly prototype the bits (the form) and the atoms (the interaction model) of physical user interfaces in concert. d.tools was built to support design thinking rather than implementation tinkering. With d.tools, designers place physical controllers (e.g., buttons, sliders), sensors (e.g., accelerometers), and output dev",
        "id": 1880,
        "title": "d.tools"
    },
    {
        "url": "http://cs.stanford.edu/content/imagenet-large-scale-hierarchical-image-database",
        "text": [
            "imagenet",
            "imagenet",
            "is",
            "an",
            "image",
            "dataset",
            "organized",
            "according",
            "to",
            "the",
            "wordnet",
            "hierarchy",
            "each",
            "meaningful",
            "concept",
            "in",
            "wordnet",
            "possibly",
            "described",
            "by",
            "multiple",
            "words",
            "or",
            "word",
            "phrases",
            "is",
            "called",
            "a",
            "synonym",
            "set",
            "or",
            "synset",
            "there",
            "are",
            "more",
            "than",
            "synsets",
            "in",
            "wordnet",
            "majority",
            "of",
            "them",
            "are",
            "nouns",
            "in",
            "imagenet",
            "we",
            "aim",
            "to",
            "provide",
            "on",
            "average",
            "images",
            "to",
            "illustrate",
            "each",
            "synset",
            "images",
            "of",
            "each",
            "concept",
            "are",
            "quality",
            "controlled",
            "and",
            "human",
            "annotated",
            "in",
            "its",
            "completion",
            "we",
            "hope",
            "imagenet",
            "will",
            "offer",
            "tens",
            "of",
            "millio"
        ],
        "content": "ImageNet.  \ufeffImageNet is an image dataset organized according to the WordNet hierarchy. Each meaningful concept in WordNet, possibly described by multiple words or word phrases, is called a \"synonym set\" or \"synset\". There are more than 100,000 synsets in WordNet, majority of them are nouns (80,000+). In ImageNet, we aim to provide on average 1000 images to illustrate each synset. Images of each concept are quality-controlled and human-annotated. In its completion, we hope ImageNet will offer tens of millio",
        "id": 1881,
        "title": "ImageNet"
    },
    {
        "url": "http://cs.stanford.edu/content/make3d",
        "text": [
            "make",
            "d",
            "an",
            "artist",
            "might",
            "spend",
            "weeks",
            "fretting",
            "over",
            "questions",
            "of",
            "depth",
            "scale",
            "and",
            "perspective",
            "in",
            "a",
            "landscape",
            "painting",
            "but",
            "once",
            "it",
            "is",
            "done",
            "what",
            "s",
            "left",
            "is",
            "a",
            "two",
            "dimensional",
            "image",
            "with",
            "a",
            "fixed",
            "point",
            "of",
            "view",
            "but",
            "the",
            "make",
            "d",
            "algorithm",
            "developed",
            "by",
            "stanford",
            "computer",
            "scientists",
            "can",
            "take",
            "any",
            "two",
            "dimensional",
            "image",
            "and",
            "create",
            "a",
            "three",
            "dimensional",
            "fly",
            "around",
            "model",
            "of",
            "its",
            "content",
            "giving",
            "viewers",
            "access",
            "to",
            "the",
            "scene",
            "s",
            "depth",
            "and",
            "a",
            "range",
            "of",
            "points",
            "of",
            "view"
        ],
        "content": "Make3d.  An artist might spend weeks fretting over questions of depth, scale and perspective in a landscape painting, but once it is done, what's left is a two-dimensional image with a fixed point of view. But the Make3d algorithm, developed by Stanford computer scientists, can take any two-dimensional image and create a three-dimensional \"fly around\" model of its content, giving viewers access to the scene's depth and a range of points of view.",
        "id": 1882,
        "title": "Make3d"
    },
    {
        "url": "http://cs.stanford.edu/content/panda",
        "text": [
            "panda",
            "panda",
            "for",
            "provenance",
            "and",
            "data",
            "is",
            "a",
            "new",
            "project",
            "whose",
            "goal",
            "is",
            "to",
            "address",
            "some",
            "limitations",
            "in",
            "existing",
            "provenance",
            "systems",
            "this",
            "short",
            "paper",
            "describes",
            "our",
            "overall",
            "plans",
            "for",
            "panda",
            "including",
            "a",
            "model",
            "that",
            "fully",
            "integrates",
            "data",
            "based",
            "and",
            "process",
            "based",
            "provenance",
            "a",
            "set",
            "of",
            "built",
            "in",
            "operators",
            "for",
            "exploiting",
            "provenance",
            "after",
            "it",
            "has",
            "been",
            "captured",
            "an",
            "ad",
            "hoc",
            "query",
            "language",
            "over",
            "provenance",
            "together",
            "with",
            "data",
            "supporting",
            "the",
            "range",
            "from",
            "fine",
            "grained",
            "to",
            "coarse",
            "grained",
            "provenance",
            "and",
            "addressing",
            "optimization"
        ],
        "content": "PANDA.  Panda (for Provenance and Data) is a new project whose goal is to address some limitations in existing provenance systems. this short paper describes our overall plans for Panda, including: a model that fully integrates data-based and process-based provenance; a set of built-in operators for exploiting provenance after it has been captured; an ad-hoc query language over provenance together with data; supporting the range from fine-grained to coarse-grained provenance; and addressing optimization",
        "id": 1883,
        "title": "PANDA"
    },
    {
        "url": "http://cs.stanford.edu/content/total-scene-understanding",
        "text": [
            "total",
            "scene",
            "understanding",
            "given",
            "an",
            "image",
            "we",
            "propose",
            "a",
            "hierarchical",
            "generative",
            "model",
            "that",
            "classifies",
            "the",
            "overall",
            "scene",
            "recognizes",
            "and",
            "segments",
            "each",
            "object",
            "component",
            "as",
            "well",
            "as",
            "annotates",
            "the",
            "image",
            "with",
            "a",
            "list",
            "of",
            "tags",
            "to",
            "our",
            "knowledge",
            "this",
            "is",
            "the",
            "first",
            "model",
            "that",
            "performs",
            "all",
            "three",
            "tasks",
            "in",
            "one",
            "coherent",
            "framework",
            "for",
            "instance",
            "a",
            "scene",
            "of",
            "a",
            "polo",
            "game",
            "consists",
            "of",
            "several",
            "visual",
            "objects",
            "such",
            "as",
            "human",
            "horse",
            "grass",
            "etc",
            "in",
            "addition",
            "it",
            "can",
            "be",
            "further",
            "annotated",
            "with",
            "a",
            "list",
            "of",
            "more",
            "abstract",
            "e",
            "g",
            "dusk",
            "or",
            "visuall"
        ],
        "content": "Total Scene Understanding.  Given an image, we propose a hierarchical generative model that classifies the overall scene, recognizes and segments each object component, as well as annotates the image with a list of tags. To our knowledge, this is the first model that performs all three tasks in one coherent framework. For instance, a scene of a \u2018polo game\u2019 consists of several visual objects such as \u2018human\u2019, \u2018horse\u2019, \u2018grass\u2019, etc. In addition, it can be further annotated with a list of more abstract (e.g. \u2018dusk\u2019) or visuall",
        "id": 1884,
        "title": "Total Scene Understanding"
    },
    {
        "url": "http://cs.stanford.edu/content/voice-based-social-media-developing-regions",
        "text": [
            "voice",
            "based",
            "social",
            "media",
            "for",
            "developing",
            "regions",
            "social",
            "software",
            "email",
            "blogs",
            "wikis",
            "forums",
            "social",
            "networks",
            "has",
            "revolutionized",
            "how",
            "people",
            "share",
            "expertise",
            "and",
            "collaborate",
            "on",
            "the",
            "web",
            "however",
            "in",
            "rural",
            "developing",
            "regions",
            "many",
            "do",
            "not",
            "have",
            "direct",
            "access",
            "to",
            "internet",
            "connected",
            "pcs",
            "or",
            "the",
            "literacy",
            "skills",
            "to",
            "interact",
            "with",
            "textual",
            "content",
            "how",
            "might",
            "we",
            "design",
            "a",
            "communications",
            "platform",
            "for",
            "these",
            "communities",
            "in",
            "our",
            "research",
            "we",
            "are",
            "designing",
            "voice",
            "based",
            "applications",
            "for",
            "communities",
            "in",
            "rural",
            "india",
            "to",
            "access",
            "agricultural",
            "advice",
            "and",
            "share",
            "expertise"
        ],
        "content": "Voice-Based Social Media for Developing Regions.  Social software \u2013 email, blogs, wikis, forums, social networks \u2013 has revolutionized how people share expertise and collaborate on the web. However, in rural developing regions, many do not have direct access to Internet-connected PCs or the literacy skills to interact with textual content. How might we design a communications platform for these communities? In our research, we are designing voice-based applications for communities in rural India to access agricultural advice and share expertise,",
        "id": 1885,
        "title": "Voice-Based Social Media for Developing Regions"
    },
    {
        "url": "http://cs.stanford.edu/research/opportunistic-programming",
        "text": [
            "opportunistic",
            "programming",
            "who",
            "will",
            "be",
            "writing",
            "software",
            "in",
            "the",
            "future",
            "and",
            "how",
            "will",
            "they",
            "be",
            "doing",
            "it",
            "as",
            "computing",
            "becomes",
            "increasingly",
            "important",
            "in",
            "people",
            "s",
            "work",
            "andhobbies",
            "a",
            "much",
            "broader",
            "range",
            "of",
            "people",
            "are",
            "engaging",
            "in",
            "programming",
            "understanding",
            "and",
            "building",
            "tools",
            "for",
            "professional",
            "software",
            "developers",
            "has",
            "a",
            "long",
            "history",
            "but",
            "there",
            "has",
            "been",
            "relatively",
            "little",
            "research",
            "on",
            "how",
            "to",
            "support",
            "amateur",
            "opportunistic",
            "programmers",
            "professor",
            "scott",
            "r",
            "klemmer",
            "s",
            "nsf",
            "funded",
            "research",
            "group",
            "at",
            "stanford",
            "university",
            "is",
            "currently",
            "studying",
            "thi"
        ],
        "content": "Opportunistic Programming.  Who will be writing software in the future and how will they be doing it? As computing becomes increasingly important in people's work andhobbies, a much broader range of people are engaging in programming. Understanding and building tools for professional software developers has a long history, but there has been relatively little research on how to support amateur, opportunistic programmers. Professor Scott R. Klemmer's NSF-funded research group at Stanford University is currently studying thi",
        "id": 1886,
        "title": "Opportunistic Programming"
    }
]