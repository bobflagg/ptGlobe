[
    {
        "url": "http://research.microsoft.com/en-us/projects/3dsurfacecomputing/",
        "text": [
            "d",
            "surface",
            "computing",
            "this",
            "project",
            "investigates",
            "techniques",
            "to",
            "enable",
            "interaction",
            "with",
            "d",
            "virtual",
            "worlds",
            "on",
            "interactive",
            "tabletops",
            "we",
            "investigate",
            "techniques",
            "to",
            "extend",
            "the",
            "display",
            "space",
            "beyond",
            "the",
            "display",
            "using",
            "among",
            "others",
            "switchable",
            "projection",
            "screens",
            "another",
            "area",
            "of",
            "interest",
            "is",
            "sensing",
            "of",
            "d",
            "input",
            "data",
            "above",
            "d",
            "surfaces",
            "here",
            "we",
            "re",
            "presenting",
            "a",
            "number",
            "of",
            "interaction",
            "technique",
            "that",
            "enable",
            "fine",
            "grained",
            "manipulations",
            "of",
            "virtual",
            "d",
            "worlds"
        ],
        "content": "3D Surface Computing.  This project investigates techniques to enable interaction with 3D virtual worlds on interactive tabletops. We investigate techniques to extend the display space beyond the display using among others switchable projection screens. Another area of interest is sensing of 3D input data above 2D surfaces. Here we're presenting a number of interaction technique that enable fine-grained manipulations of virtual 3D worlds.",
        "id": 2131,
        "title": "3D Surface Computing"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/augmentedprojectors/default.aspx",
        "text": [
            "augmented",
            "projectors",
            "in",
            "this",
            "project",
            "we",
            "investig",
            "novel",
            "handheld",
            "projector",
            "systems",
            "for",
            "indoor",
            "pervasive",
            "computing",
            "spaces",
            "these",
            "projection",
            "based",
            "devices",
            "are",
            "aware",
            "of",
            "their",
            "environment",
            "in",
            "ways",
            "not",
            "demonstrated",
            "previously",
            "they",
            "offer",
            "both",
            "spatial",
            "awareness",
            "where",
            "the",
            "system",
            "infers",
            "location",
            "and",
            "orientation",
            "of",
            "the",
            "device",
            "in",
            "d",
            "space",
            "and",
            "geometry",
            "awareness",
            "where",
            "the",
            "system",
            "constructs",
            "the",
            "d",
            "structure",
            "of",
            "the",
            "world",
            "around",
            "it",
            "which",
            "can",
            "encompass",
            "the",
            "user",
            "as",
            "well",
            "as",
            "other",
            "physical",
            "objects",
            "such",
            "as",
            "furniture",
            "and",
            "walls"
        ],
        "content": "Augmented Projectors.  in this project we investig novel handheld projector systems for indoor pervasive computing spaces. These projection-based devices are \u201caware\u201d of their environment in ways not demonstrated previously. They offer both spatial awareness, where the system infers location and orientation of the device in 3D space, and geometry awareness, where the system constructs the 3D structure of the world around it, which can encompass the user as well as other physical objects, such as furniture and walls.",
        "id": 2132,
        "title": "Augmented Projectors"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/bookviz/default.aspx",
        "text": [
            "visualizing",
            "the",
            "text",
            "of",
            "children",
            "s",
            "book",
            "series",
            "a",
            "stream",
            "of",
            "dancing",
            "lights",
            "for",
            "all",
            "the",
            "world",
            "like",
            "the",
            "shimmering",
            "curtains",
            "of",
            "the",
            "aurora",
            "blazed",
            "across",
            "the",
            "screen",
            "they",
            "took",
            "up",
            "patterns",
            "that",
            "were",
            "held",
            "for",
            "a",
            "moment",
            "only",
            "to",
            "break",
            "apart",
            "and",
            "form",
            "again",
            "in",
            "different",
            "shapes",
            "or",
            "different",
            "colours",
            "they",
            "looped",
            "and",
            "swayed",
            "they",
            "sprayed",
            "apart",
            "they",
            "burst",
            "into",
            "showers",
            "of",
            "radiance",
            "that",
            "suddenly",
            "swerved",
            "this",
            "way",
            "or",
            "that",
            "like",
            "a",
            "flock",
            "of",
            "birds",
            "changing",
            "direction",
            "in",
            "the",
            "sky",
            "and",
            "as",
            "lyra",
            "watched",
            "she",
            "felt",
            "the",
            "same",
            "sense",
            "as",
            "of",
            "trembling",
            "on",
            "the",
            "brink",
            "of",
            "under"
        ],
        "content": "Visualizing the text of (children's) book series.  A stream of dancing lights, for all the world like the shimmering curtains of the aurora, blazed across the screen. They took up patterns that were held for a moment only to break apart and form again, in different shapes, or different colours; they looped and swayed, they sprayed apart, they burst into showers of radiance that suddenly swerved this way or that like a flock of birds changing direction in the sky. And as Lyra watched, she felt the same sense, as of trembling on the brink of under",
        "id": 2133,
        "title": "Visualizing the text of (children's) book series"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/c-slate/",
        "text": [
            "c",
            "slate",
            "the",
            "c",
            "slate",
            "project",
            "is",
            "developing",
            "a",
            "teleconferencing",
            "system",
            "that",
            "enables",
            "easy",
            "and",
            "efficient",
            "electronic",
            "two",
            "way",
            "collaboration",
            "in",
            "the",
            "workplace",
            "the",
            "aim",
            "is",
            "to",
            "define",
            "a",
            "reference",
            "workstation",
            "for",
            "collaboration",
            "between",
            "knowledge",
            "workers",
            "that",
            "allows",
            "the",
            "sharing",
            "of",
            "tasks",
            "with",
            "sufficient",
            "intensity",
            "clarity",
            "and",
            "effectiveness",
            "that",
            "travel",
            "with",
            "its",
            "attendant",
            "waste",
            "of",
            "resources",
            "and",
            "creative",
            "time",
            "is",
            "rendered",
            "unnecessary",
            "in",
            "many",
            "cases"
        ],
        "content": "C-Slate.  The C-Slate project is developing a teleconferencing system that enables easy and efficient electronic two-way collaboration in the workplace. The aim is to define a reference workstation for collaboration between knowledge workers that allows the sharing of tasks with sufficient intensity, clarity and effectiveness that travel, with its attendant waste of resources and creative time, is rendered unnecessary in many cases.",
        "id": 2134,
        "title": "C-Slate"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/greenwich/",
        "text": [
            "project",
            "greenwich",
            "project",
            "greenwich",
            "is",
            "a",
            "website",
            "that",
            "allows",
            "people",
            "to",
            "create",
            "timelines",
            "of",
            "any",
            "subject",
            "they",
            "want",
            "to",
            "present",
            "chronologically",
            "using",
            "the",
            "site",
            "they",
            "could",
            "show",
            "the",
            "lifespan",
            "of",
            "an",
            "individual",
            "how",
            "a",
            "historical",
            "event",
            "evolved",
            "or",
            "how",
            "a",
            "place",
            "changed",
            "for",
            "example",
            "with",
            "greenwich",
            "we",
            "are",
            "interested",
            "in",
            "researching",
            "how",
            "people",
            "think",
            "about",
            "time",
            "how",
            "they",
            "go",
            "about",
            "the",
            "process",
            "of",
            "telling",
            "a",
            "story",
            "through",
            "time",
            "and",
            "what",
            "it",
            "means",
            "to",
            "reflect",
            "on",
            "chronological",
            "content",
            "to",
            "think",
            "about",
            "the",
            "past"
        ],
        "content": "Project Greenwich.  Project Greenwich is a website that allows people to create timelines of any subject they want to present chronologically. Using the site they could show the lifespan of an individual, how a historical event evolved, or how a place changed, for example. With Greenwich we are interested in researching how people think about time, how they go about the process of telling a story through time, and what it means to reflect on chronological content to think about the past.",
        "id": 2135,
        "title": "Project Greenwich"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/hands-on-computing/surfacephysics.aspx",
        "text": [
            "surface",
            "physics",
            "surface",
            "physics",
            "explores",
            "new",
            "ways",
            "of",
            "supporting",
            "multi",
            "touch",
            "and",
            "whole",
            "hand",
            "interaction",
            "on",
            "digital",
            "surfaces",
            "our",
            "aim",
            "is",
            "to",
            "bring",
            "the",
            "digital",
            "to",
            "life",
            "allowing",
            "interactions",
            "with",
            "digital",
            "objects",
            "to",
            "simulate",
            "the",
            "physics",
            "of",
            "the",
            "real",
            "world",
            "we",
            "use",
            "an",
            "advanced",
            "physics",
            "engine",
            "to",
            "add",
            "dynamics",
            "to",
            "digital",
            "objects",
            "allowing",
            "them",
            "to",
            "behave",
            "more",
            "like",
            "real",
            "objects",
            "when",
            "we",
            "touch",
            "them",
            "with",
            "notions",
            "of",
            "inertia",
            "collisions",
            "friction",
            "restitution",
            "and",
            "so",
            "forth",
            "our",
            "contribution",
            "in",
            "this",
            "work",
            "is",
            "a",
            "novel",
            "technique",
            "fo"
        ],
        "content": "Surface Physics.  Surface Physics explores new ways of supporting multi-touch and whole hand interaction on digital surfaces. Our aim is to bring the digital to \u2018life\u2019, allowing interactions with digital objects to simulate the physics of the real-world. We use an advanced physics-engine to add dynamics to digital objects, allowing them to behave more like real objects when we touch them, with notions of inertia, collisions, friction, restitution and so forth. Our contribution in this work is a novel technique fo",
        "id": 2136,
        "title": "Surface Physics"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/heirlooms/default.aspx",
        "text": [
            "technology",
            "heirlooms",
            "this",
            "project",
            "is",
            "all",
            "about",
            "thinking",
            "about",
            "technology",
            "in",
            "the",
            "long",
            "term",
            "while",
            "we",
            "tend",
            "to",
            "think",
            "of",
            "most",
            "digital",
            "things",
            "as",
            "only",
            "having",
            "a",
            "shelf",
            "life",
            "of",
            "a",
            "few",
            "years",
            "the",
            "reality",
            "is",
            "that",
            "we",
            "re",
            "now",
            "taking",
            "digital",
            "photos",
            "and",
            "keeping",
            "digital",
            "items",
            "for",
            "long",
            "enough",
            "that",
            "we",
            "have",
            "to",
            "start",
            "thinking",
            "about",
            "the",
            "consequences",
            "of",
            "using",
            "them",
            "for",
            "reminiscing",
            "in",
            "the",
            "future",
            "and",
            "even",
            "passing",
            "them",
            "on",
            "to",
            "our",
            "offspring",
            "what",
            "does",
            "it",
            "mean",
            "to",
            "inherit",
            "someone",
            "s",
            "pc",
            "or",
            "to",
            "use",
            "digital",
            "technology",
            "to",
            "reflect",
            "on",
            "someone",
            "s",
            "life"
        ],
        "content": "Technology Heirlooms.  This project is all about thinking about technology in the long term. While we tend to think of most digital things as only having a shelf life of a few years, the reality is that we're now taking digital photos, and keeping digital items, for long enough that we have to start thinking about the consequences of using them for reminiscing in the future, and even passing them on to our offspring. What does it mean to inherit someone's PC or to use digital technology to reflect on someone's life?",
        "id": 2137,
        "title": "Technology Heirlooms"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/lightspace/",
        "text": [
            "lightspace",
            "lightspace",
            "combines",
            "elements",
            "of",
            "surface",
            "computing",
            "and",
            "augmented",
            "reality",
            "research",
            "to",
            "create",
            "a",
            "highly",
            "interactive",
            "space",
            "where",
            "any",
            "surface",
            "and",
            "even",
            "the",
            "space",
            "between",
            "surfaces",
            "is",
            "fully",
            "interactive",
            "our",
            "concept",
            "transforms",
            "the",
            "ideas",
            "of",
            "surface",
            "computing",
            "into",
            "the",
            "new",
            "realm",
            "of",
            "spatial",
            "computing"
        ],
        "content": "LightSpace.  LightSpace combines elements of surface computing and augmented reality research to create a highly interactive space where any surface, and even the space between surfaces, is fully interactive. Our concept transforms the ideas of surface computing into the new realm of spatial computing.",
        "id": 2138,
        "title": "LightSpace"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/mirageblocks/",
        "text": [
            "mirageblocks",
            "digitize",
            "objects",
            "and",
            "interact",
            "with",
            "them",
            "on",
            "a",
            "projected",
            "augmented",
            "reality",
            "desk",
            "mirageblocks",
            "demo",
            "showcases",
            "the",
            "use",
            "of",
            "d",
            "stereo",
            "projection",
            "combined",
            "with",
            "kinect",
            "camera",
            "to",
            "capture",
            "display",
            "and",
            "interact",
            "with",
            "d",
            "objects",
            "any",
            "physical",
            "object",
            "can",
            "instantly",
            "be",
            "virtualized",
            "and",
            "then",
            "interacted",
            "with",
            "with",
            "bare",
            "hands",
            "using",
            "a",
            "realistic",
            "physical",
            "simulation"
        ],
        "content": "MirageBlocks: Digitize objects and interact with them on a projected augmented reality desk.  MirageBlocks demo showcases the use of 3D stereo projection combined with Kinect camera to capture, display, and interact with 3D objects.\nAny physical object can instantly be virtualized and then interacted with with bare hands using a realistic physical simulation.",
        "id": 2139,
        "title": "MirageBlocks: Digitize objects and interact with them on a projected augmented reality desk"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/objectclassrecognition/default.aspx",
        "text": [
            "image",
            "understanding",
            "at",
            "microsoft",
            "research",
            "in",
            "cambridge",
            "we",
            "are",
            "developing",
            "new",
            "machine",
            "vision",
            "algorithms",
            "for",
            "automatic",
            "recognition",
            "and",
            "segmentation",
            "of",
            "many",
            "different",
            "object",
            "categories",
            "we",
            "are",
            "interested",
            "in",
            "both",
            "the",
            "supervised",
            "and",
            "unsupervised",
            "scenarios"
        ],
        "content": "Image Understanding.  At Microsoft Research in Cambridge we are developing new machine vision algorithms for automatic recognition and segmentation of many different object categories. We are interested in both the supervised and unsupervised scenarios.",
        "id": 2140,
        "title": "Image Understanding"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/serendipitousdisplays/default.aspx",
        "text": [
            "serendipitous",
            "displays",
            "over",
            "the",
            "years",
            "as",
            "digital",
            "technologies",
            "have",
            "become",
            "more",
            "and",
            "more",
            "embedded",
            "into",
            "our",
            "everyday",
            "lives",
            "people",
            "are",
            "beginning",
            "to",
            "accumulate",
            "vast",
            "amounts",
            "of",
            "personal",
            "digital",
            "content",
            "through",
            "their",
            "interactions",
            "with",
            "digital",
            "capturing",
            "technologies",
            "social",
            "networking",
            "sites",
            "their",
            "continuous",
            "endeavors",
            "with",
            "the",
            "web",
            "and",
            "simple",
            "things",
            "new",
            "content",
            "such",
            "as",
            "music",
            "photos",
            "videos",
            "tweets",
            "and",
            "facebook",
            "posts",
            "is",
            "being",
            "generated",
            "and",
            "collected",
            "with",
            "this",
            "these",
            "collections",
            "often",
            "become",
            "more",
            "unwieldy",
            "with",
            "the",
            "desig"
        ],
        "content": "Serendipitous Displays.  Over the years, as digital technologies have become more and more embedded into our everyday lives, people are beginning to accumulate vast amounts of personal digital content through their interactions with digital capturing technologies, social networking sites, their continuous endeavors with the web and simple things, new content such as music, photos, videos, Tweets, and Facebook posts, is being generated and collected. With this, these collections often become more unwieldy. With the desig",
        "id": 2141,
        "title": "Serendipitous Displays"
    },
    {
        "url": "http://research.microsoft.com/en-us/projects/surfacerecon/",
        "text": [
            "kinectfusion",
            "project",
            "page",
            "this",
            "project",
            "investigates",
            "techniques",
            "to",
            "track",
            "the",
            "dof",
            "position",
            "of",
            "handheld",
            "depth",
            "sensing",
            "cameras",
            "such",
            "as",
            "kinect",
            "as",
            "they",
            "move",
            "through",
            "space",
            "and",
            "perform",
            "high",
            "quality",
            "d",
            "surface",
            "reconstructions",
            "for",
            "interaction",
            "other",
            "collaborators",
            "missing",
            "from",
            "the",
            "list",
            "below",
            "richard",
            "newcombe",
            "imperial",
            "college",
            "london",
            "david",
            "kim",
            "newcastle",
            "university",
            "microsoft",
            "research",
            "andy",
            "davison",
            "imperial",
            "college",
            "london"
        ],
        "content": "KinectFusion Project Page.  This project investigates techniques to track the 6DOF position of handheld depth sensing cameras, such as Kinect, as they move through space and perform high quality 3D surface reconstructions for interaction.\nOther collaborators (missing from the list below):\nRichard Newcombe (Imperial College London);\nDavid Kim (Newcastle University & Microsoft Research);\nAndy Davison (Imperial College London)",
        "id": 2142,
        "title": "KinectFusion Project Page"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/beijing/groups/hci/",
        "text": [
            "cross",
            "cultural",
            "design",
            "in",
            "this",
            "research",
            "we",
            "are",
            "aiming",
            "to",
            "understand",
            "how",
            "to",
            "design",
            "better",
            "websites",
            "for",
            "chinese",
            "users",
            "we",
            "will",
            "examine",
            "the",
            "effects",
            "of",
            "individual",
            "differences",
            "national",
            "culture",
            "and",
            "different",
            "task",
            "types",
            "on",
            "implications",
            "of",
            "web",
            "user",
            "interface",
            "design",
            "through",
            "a",
            "a",
            "b",
            "testing",
            "survey",
            "study",
            "we",
            "are",
            "able",
            "to",
            "answer",
            "what",
            "are",
            "key",
            "factors",
            "to",
            "drive",
            "customer",
            "satisfaction",
            "and",
            "loyalty",
            "through",
            "quantitative",
            "statistical",
            "analysis",
            "of",
            "our",
            "survey",
            "data"
        ],
        "content": "Cross-Cultural Design.  In this research, we are aiming to understand how to design better websites for Chinese users.  We will examine the effects of individual differences, national culture and different task types on implications of web user interface design through a A/B testing survey study. We are able to answer what are key factors to drive customer satisfaction and loyalty through quantitative statistical analysis of our survey data.",
        "id": 2143,
        "title": "Cross-Cultural Design"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/people/benko/projects/sphere/",
        "text": [
            "sphere",
            "a",
            "multi",
            "touch",
            "interactive",
            "spherical",
            "display",
            "our",
            "prototype",
            "device",
            "builds",
            "on",
            "a",
            "commercially",
            "available",
            "globe",
            "projection",
            "system",
            "global",
            "imagination",
            "s",
            "magic",
            "planet",
            "we",
            "have",
            "added",
            "touch",
            "sensing",
            "capabilities",
            "with",
            "an",
            "infrared",
            "camera",
            "that",
            "shares",
            "the",
            "optical",
            "path",
            "with",
            "the",
            "projector",
            "this",
            "novel",
            "configuration",
            "permits",
            "us",
            "to",
            "enclose",
            "both",
            "the",
            "projection",
            "and",
            "the",
            "sensing",
            "mechanism",
            "in",
            "the",
            "base",
            "of",
            "the",
            "device",
            "and",
            "allows",
            "for",
            "easy",
            "degrees",
            "access",
            "to",
            "the",
            "device",
            "and",
            "high",
            "degree",
            "of",
            "interactivity",
            "without",
            "shadowing",
            "or",
            "occlusion",
            "problems",
            "we",
            "have",
            "also",
            "developed"
        ],
        "content": "Sphere: A Multi-Touch Interactive Spherical Display.  Our prototype device builds on a commercially available globe\nprojection system (Global\nImagination\ufffds Magic Planet). We have added touch-sensing capabilities with\nan infrared camera that shares the optical path with the projector. This novel\nconfiguration permits us to enclose both the projection and the sensing\nmechanism in the base of the device and allows for easy 360 degrees access to\nthe device and high degree of interactivity without shadowing or occlusion\nproblems. We have also developed ",
        "id": 2144,
        "title": "Sphere: A Multi-Touch Interactive Spherical Display"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/people/kopf/street_slide/index.html",
        "text": [
            "street",
            "slide",
            "abstract",
            "systems",
            "such",
            "as",
            "google",
            "street",
            "view",
            "and",
            "bing",
            "maps",
            "streetside",
            "enable",
            "users",
            "to",
            "virtually",
            "visit",
            "cities",
            "by",
            "navigating",
            "between",
            "immersive",
            "panoramas",
            "or",
            "bubbles",
            "the",
            "discrete",
            "moves",
            "from",
            "bubble",
            "to",
            "bubble",
            "enabled",
            "in",
            "these",
            "systems",
            "do",
            "not",
            "provide",
            "a",
            "good",
            "visual",
            "sense",
            "of",
            "a",
            "larger",
            "aggregate",
            "such",
            "as",
            "a",
            "whole",
            "city",
            "block",
            "multi",
            "perspective",
            "strip",
            "panoramas",
            "can",
            "provide",
            "a",
            "visual",
            "summary",
            "of",
            "a",
            "city",
            "street",
            "but",
            "lack",
            "the",
            "full",
            "realism",
            "of",
            "immersive",
            "panoramas",
            "we",
            "present",
            "street",
            "slide",
            "which",
            "combines",
            "the",
            "best"
        ],
        "content": "Street Slide.  Abstract\nSystems such as Google Street View and Bing Maps Streetside enable\nusers to virtually visit cities by navigating between immersive\n360\u00b0  panoramas, or bubbles. The discrete moves from bubble to\nbubble enabled in these systems do not provide a good visual sense\nof a larger aggregate such as a whole city block. Multi-perspective\n\"strip\" panoramas can provide a visual summary of a city street but\nlack the full realism of immersive panoramas.\nWe present Street Slide, which combines the best",
        "id": 2145,
        "title": "Street Slide"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/IML/",
        "text": [
            "cuetip",
            "mixed",
            "initiative",
            "handwriting",
            "recognition",
            "handwritten",
            "input",
            "is",
            "inherently",
            "ambiguous",
            "and",
            "recognition",
            "systems",
            "will",
            "always",
            "make",
            "errors",
            "unfortunately",
            "work",
            "on",
            "error",
            "recovery",
            "mechanisms",
            "has",
            "mainly",
            "focused",
            "on",
            "interface",
            "innovations",
            "that",
            "allow",
            "users",
            "to",
            "manually",
            "transform",
            "the",
            "erroneous",
            "recognition",
            "result",
            "into",
            "the",
            "intended",
            "one",
            "in",
            "our",
            "work",
            "we",
            "propose",
            "a",
            "mixed",
            "initiative",
            "approach",
            "to",
            "error",
            "correction",
            "cuetip",
            "is",
            "a",
            "novel",
            "correction",
            "interface",
            "that",
            "takes",
            "advantage",
            "of",
            "the",
            "recognizer",
            "to",
            "continually",
            "evolve",
            "its",
            "results",
            "using",
            "the",
            "additional",
            "information",
            "fr"
        ],
        "content": "CueTIP: Mixed-Initiative Handwriting Recognition.  Handwritten input is inherently ambiguous, and recognition\nsystems will always make errors. Unfortunately, work on error recovery mechanisms has\nmainly focused on interface innovations that allow users to manually transform the erroneous\nrecognition result into the intended one. In our work, we propose a mixed-initiative approach\nto error correction. CueTIP is a novel correction interface that takes advantage of the\nrecognizer to continually evolve its results using the additional information fr",
        "id": 2146,
        "title": "CueTIP: Mixed-Initiative Handwriting Recognition"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/crossdevice/",
        "text": [
            "patterns",
            "of",
            "pc",
            "and",
            "smartphone",
            "use",
            "research",
            "has",
            "demonstrated",
            "that",
            "information",
            "workers",
            "often",
            "manage",
            "several",
            "different",
            "computing",
            "devices",
            "in",
            "an",
            "effort",
            "to",
            "balance",
            "convenience",
            "mobility",
            "input",
            "efficiency",
            "and",
            "content",
            "readability",
            "throughout",
            "their",
            "day",
            "to",
            "understand",
            "how",
            "future",
            "technologies",
            "might",
            "better",
            "support",
            "productivity",
            "tasks",
            "as",
            "people",
            "transition",
            "between",
            "devices",
            "we",
            "examined",
            "the",
            "mobile",
            "phone",
            "and",
            "pc",
            "usage",
            "patterns",
            "of",
            "sixteen",
            "information",
            "workers",
            "across",
            "several",
            "weeks",
            "our",
            "data",
            "logs",
            "together",
            "with",
            "follow",
            "up",
            "interview",
            "feedback",
            "from",
            "four",
            "o"
        ],
        "content": "Patterns of PC and Smartphone Use.  Research has demonstrated that information workers often manage several different computing devices in an effort to balance convenience, mobility, input efficiency, and content readability throughout their day. To understand how future technologies might better support productivity tasks as people transition between devices, we examined the mobile phone and PC usage patterns of sixteen information workers across several weeks. Our data logs, together with follow-up interview feedback from four o",
        "id": 2147,
        "title": "Patterns of PC and Smartphone Use"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/homeautomation/",
        "text": [
            "homeos",
            "and",
            "homestore",
            "to",
            "simplify",
            "the",
            "management",
            "of",
            "technology",
            "in",
            "the",
            "home",
            "and",
            "to",
            "simplify",
            "the",
            "development",
            "of",
            "applications",
            "in",
            "the",
            "home",
            "we",
            "are",
            "developing",
            "an",
            "operating",
            "system",
            "for",
            "the",
            "home",
            "our",
            "operating",
            "system",
            "called",
            "homeos",
            "provides",
            "a",
            "centralized",
            "holistic",
            "control",
            "of",
            "devices",
            "in",
            "the",
            "home",
            "it",
            "is",
            "backed",
            "by",
            "a",
            "homestore",
            "that",
            "simplifies",
            "for",
            "users",
            "the",
            "task",
            "of",
            "obtaining",
            "applications",
            "and",
            "devices",
            "that",
            "work",
            "well",
            "with",
            "existing",
            "technology",
            "in",
            "the",
            "home",
            "homeos",
            "is",
            "a",
            "collaboration",
            "between",
            "the",
            "networking",
            "group",
            "and",
            "cue",
            "group",
            "the",
            "co"
        ],
        "content": "HomeOs and HomeStore.  To simplify the management of technology in the home and to simplify the development of applications in the home, we are developing an operating system for the home. Our operating system, called HomeOS, provides a centralized, holistic control of devices in the home. It is backed by a HomeStore that simplifies for users the task of obtaining applications and devices that work well with existing technology in the home.  HomeOs is a collaboration between the Networking Group and CUE group.  The co",
        "id": 2148,
        "title": "HomeOs and HomeStore"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/humAntenna/",
        "text": [
            "humantenna",
            "sensing",
            "gestures",
            "using",
            "the",
            "body",
            "as",
            "an",
            "antenna",
            "computer",
            "vision",
            "and",
            "inertial",
            "measurement",
            "have",
            "made",
            "it",
            "possible",
            "for",
            "people",
            "to",
            "interact",
            "with",
            "computers",
            "using",
            "whole",
            "body",
            "gestures",
            "although",
            "there",
            "has",
            "been",
            "rapid",
            "growth",
            "in",
            "the",
            "uses",
            "and",
            "applications",
            "of",
            "these",
            "systems",
            "their",
            "ubiquity",
            "has",
            "been",
            "limited",
            "by",
            "the",
            "high",
            "cost",
            "of",
            "heavily",
            "instrumenting",
            "either",
            "the",
            "environment",
            "or",
            "the",
            "user",
            "in",
            "this",
            "paper",
            "we",
            "use",
            "the",
            "human",
            "body",
            "as",
            "an",
            "antenna",
            "for",
            "sensing",
            "whole",
            "body",
            "gestures",
            "such",
            "an",
            "approach",
            "requires",
            "no",
            "instrumentation",
            "to",
            "the",
            "environment",
            "and",
            "only",
            "minimal",
            "instrumentat"
        ],
        "content": "Humantenna:Sensing Gestures Using the Body as an Antenna.  Computer vision and inertial measurement have made it possible for people to interact with computers using whole-body gestures. Although there has been rapid growth in the uses and applications of these systems, their ubiquity has been limited by the high cost of heavily instrumenting either the environment or the user. In this paper, we use the human body as an antenna for sensing whole-body gestures. Such an approach requires no instrumentation to the environment, and only minimal instrumentat",
        "id": 2149,
        "title": "Humantenna:Sensing Gestures Using the Body as an Antenna"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/infovis/",
        "text": [
            "facetlens",
            "facetlens",
            "is",
            "a",
            "follow",
            "on",
            "interface",
            "to",
            "prior",
            "work",
            "on",
            "facetmap",
            "and",
            "paperlens",
            "facetlens",
            "is",
            "an",
            "appropriate",
            "visualization",
            "tool",
            "for",
            "nearly",
            "any",
            "item",
            "attribute",
            "based",
            "dataset",
            "expressed",
            "as",
            "a",
            "sql",
            "database",
            "provided",
            "with",
            "a",
            "description",
            "of",
            "the",
            "types",
            "and",
            "locations",
            "of",
            "item",
            "metadata",
            "facetlens",
            "dynamically",
            "generates",
            "sql",
            "queries",
            "to",
            "probe",
            "the",
            "data",
            "distributions",
            "and",
            "present",
            "them",
            "to",
            "the",
            "user",
            "in",
            "a",
            "data",
            "rich",
            "animated",
            "way",
            "the",
            "user",
            "can",
            "interactively",
            "click",
            "on",
            "values",
            "to",
            "apply",
            "filter",
            "criteria",
            "and",
            "can",
            "use",
            "drag",
            "drop",
            "oper"
        ],
        "content": "FacetLens.  FacetLens is a follow-on interface\nto prior work on FacetMap and PaperLens. FacetLens is an\nappropriate visualization tool for nearly any item/attribute\nbased dataset expressed as a SQL database. Provided with a\ndescription of the types and locations of item metadata,\nFacetLens dynamically generates SQL queries to probe the data\ndistributions and present them to the user in a data-rich,\nanimated way. The user can\u00a0 interactively click on values to\napply filter criteria, and can use drag/drop oper",
        "id": 2150,
        "title": "FacetLens"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/mobilenui/",
        "text": [
            "skinput",
            "bioacoustic",
            "sensing",
            "for",
            "input",
            "we",
            "present",
            "skinput",
            "a",
            "technology",
            "that",
            "appropriates",
            "the",
            "human",
            "body",
            "for",
            "acoustic",
            "transmission",
            "allowing",
            "the",
            "skin",
            "to",
            "be",
            "used",
            "as",
            "an",
            "input",
            "surface",
            "in",
            "particular",
            "we",
            "resolve",
            "the",
            "location",
            "of",
            "finger",
            "taps",
            "on",
            "the",
            "arm",
            "and",
            "hand",
            "by",
            "analyzing",
            "mechanical",
            "vibrations",
            "that",
            "propagate",
            "through",
            "the",
            "body"
        ],
        "content": "Skinput: Bioacoustic Sensing for Input.  We present Skinput, a technology that appropriates the human body for acoustic transmission, allowing the skin to be used as an input surface. In particular, we resolve the location of finger taps on the arm and hand by analyzing mechanical vibrations that propagate through the body.",
        "id": 2151,
        "title": "Skinput: Bioacoustic Sensing for Input"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/soundwave/",
        "text": [
            "soundwave",
            "using",
            "the",
            "doppler",
            "effect",
            "to",
            "sense",
            "gestures",
            "gesture",
            "is",
            "becoming",
            "an",
            "increasingly",
            "popular",
            "means",
            "of",
            "interacting",
            "with",
            "computers",
            "however",
            "it",
            "is",
            "still",
            "relatively",
            "costly",
            "to",
            "deploy",
            "robust",
            "gesture",
            "recognition",
            "sensors",
            "in",
            "existing",
            "mobile",
            "platforms",
            "we",
            "present",
            "soundwave",
            "a",
            "technique",
            "that",
            "leverages",
            "the",
            "speaker",
            "and",
            "microphone",
            "already",
            "embedded",
            "in",
            "most",
            "commodity",
            "devices",
            "to",
            "sense",
            "in",
            "air",
            "gestures",
            "around",
            "the",
            "device",
            "to",
            "do",
            "this",
            "we",
            "generate",
            "an",
            "inaudible",
            "tone",
            "which",
            "gets",
            "frequency",
            "shifted",
            "when",
            "it",
            "reflects",
            "off",
            "moving",
            "objects",
            "like",
            "the",
            "hand",
            "we",
            "measure",
            "this",
            "shi"
        ],
        "content": "SoundWave:Using the Doppler Effect to Sense Gestures.  Gesture is becoming an increasingly popular means of interacting with computers. However, it is still relatively costly\nto deploy robust gesture recognition sensors in existing mobile platforms. We present SoundWave, a technique that leverages\nthe speaker and microphone already embedded in most commodity devices to sense in-air gestures around the device. To do this,\nwe generate an inaudible tone, which gets frequency-shifted when it reflects off moving objects like the hand. We measure\nthis shi",
        "id": 2152,
        "title": "SoundWave:Using the Doppler Effect to Sense Gestures"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/cue/voicetyping/",
        "text": [
            "a",
            "new",
            "speech",
            "interaction",
            "model",
            "for",
            "dictationon",
            "touchscreen",
            "devices",
            "we",
            "are",
            "exploring",
            "a",
            "multi",
            "modal",
            "interface",
            "that",
            "helps",
            "people",
            "type",
            "with",
            "speech",
            "by",
            "providing",
            "them",
            "with",
            "real",
            "time",
            "feedback",
            "while",
            "they",
            "are",
            "speaking",
            "phrases",
            "as",
            "a",
            "chuck",
            "and",
            "by",
            "allowing",
            "them",
            "to",
            "correct",
            "any",
            "mistakes",
            "with",
            "both",
            "speech",
            "and",
            "touch"
        ],
        "content": "A New Speech Interaction Model for Dictationon Touchscreen Devices.  We are exploring a multi-modal interface that helps people type with speech by providing them with real-time feedback while they are speaking (phrases as a chuck) and by allowing them to correct any mistakes with both speech and touch.",
        "id": 2153,
        "title": "A New Speech Interaction Model for Dictationon Touchscreen Devices"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/PlanarStereo/",
        "text": [
            "piecewise",
            "planar",
            "stereo",
            "for",
            "image",
            "based",
            "rendering",
            "abstract",
            "we",
            "present",
            "a",
            "novel",
            "multi",
            "view",
            "stereo",
            "method",
            "designed",
            "for",
            "image",
            "based",
            "rendering",
            "that",
            "generates",
            "piecewise",
            "planar",
            "depth",
            "maps",
            "from",
            "an",
            "unordered",
            "collection",
            "of",
            "photographs",
            "first",
            "a",
            "discrete",
            "set",
            "of",
            "d",
            "plane",
            "candidates",
            "are",
            "computed",
            "based",
            "on",
            "a",
            "sparse",
            "point",
            "cloud",
            "of",
            "the",
            "scene",
            "recovered",
            "by",
            "structure",
            "from",
            "motion",
            "and",
            "sparse",
            "d",
            "line",
            "segments",
            "reconstructed",
            "from",
            "multiple",
            "views",
            "next",
            "evidence",
            "is",
            "accumulated",
            "for",
            "each",
            "plane",
            "using",
            "d",
            "point",
            "and",
            "line",
            "incidence",
            "and",
            "photo",
            "consistency",
            "cues",
            "finally",
            "a",
            "piecew"
        ],
        "content": "Piecewise Planar Stereo for Image-based Rendering.  Abstract\nWe present a novel multi-view\nstereo method designed for image-based rendering that generates piecewise\nplanar depth maps from an unordered collection of photographs. First a\ndiscrete set of 3D plane candidates are computed based on a sparse point\ncloud of the scene (recovered by structure from motion) and sparse 3D line\nsegments reconstructed from multiple views. Next, evidence is accumulated for\neach plane using 3D point and line incidence and photo-consistency cues.\nFinally, a piecew",
        "id": 2154,
        "title": "Piecewise Planar Stereo for Image-based Rendering"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/hdr/",
        "text": [
            "high",
            "dynamic",
            "range",
            "imaging",
            "when",
            "shooting",
            "digital",
            "images",
            "of",
            "many",
            "environments",
            "it",
            "is",
            "impossible",
            "to",
            "fully",
            "capture",
            "the",
            "real",
            "world",
            "dynamic",
            "range",
            "of",
            "intensities",
            "typical",
            "scene",
            "intensities",
            "can",
            "range",
            "over",
            "orders",
            "of",
            "magnitude",
            "while",
            "the",
            "best",
            "digital",
            "sensors",
            "can",
            "only",
            "capture",
            "there",
            "has",
            "been",
            "a",
            "great",
            "deal",
            "of",
            "recent",
            "effort",
            "in",
            "combining",
            "multiple",
            "exposures",
            "of",
            "a",
            "still",
            "scene",
            "to",
            "create",
            "a",
            "high",
            "dynamic",
            "range",
            "image",
            "of",
            "the",
            "scene",
            "however",
            "until",
            "now",
            "no",
            "one",
            "has",
            "done",
            "this",
            "for",
            "moving",
            "scenes",
            "or",
            "for",
            "video",
            "through",
            "a",
            "clever",
            "combination",
            "of",
            "camera",
            "fi"
        ],
        "content": "High Dynamic Range Imaging.  When shooting digital images of many environments it is impossible to fully\ncapture the real world dynamic range of intensities. Typical scene intensities\ncan range over 5 orders of magnitude while the best digital sensors can only\ncapture 3. There has been a great deal of recent effort in combining multiple\nexposures of a still scene to create a high dynamic range image of the scene.\nHowever until now no one has done this for moving scenes or for video. Through a\nclever combination of camera fi",
        "id": 2155,
        "title": "High Dynamic Range Imaging"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/hdview/",
        "text": [
            "hd",
            "view",
            "what",
            "is",
            "hd",
            "view",
            "hd",
            "view",
            "is",
            "the",
            "camera",
            "for",
            "the",
            "web",
            "its",
            "goal",
            "is",
            "to",
            "create",
            "the",
            "best",
            "picture",
            "given",
            "a",
            "a",
            "source",
            "with",
            "high",
            "resolution",
            "arbitrary",
            "dynamic",
            "range",
            "any",
            "field",
            "of",
            "view",
            "color",
            "gamut",
            "b",
            "the",
            "user",
            "s",
            "interaction",
            "and",
            "c",
            "the",
            "display",
            "being",
            "used",
            "how",
            "do",
            "i",
            "create",
            "hd",
            "view",
            "content",
            "microsoft",
            "image",
            "composite",
            "editor",
            "ice",
            "can",
            "now",
            "stitch",
            "your",
            "images",
            "and",
            "output",
            "directly",
            "to",
            "hd",
            "view",
            "or",
            "the",
            "new",
            "platform",
            "independent",
            "hd",
            "view",
            "sl",
            "you",
            "can",
            "also",
            "use",
            "our",
            "photoshop",
            "plugin",
            "or",
            "the",
            "hdmake",
            "command",
            "line",
            "utility",
            "g"
        ],
        "content": "HD View.  What is HD View?\nHD View is the camera for the web.\nIts goal is to create the best picture given\n(a) a source\nwith\nhigh resolution, arbitrary\ndynamic range, any\nfield of view & color gamut; (b)\nthe user\u2019s interaction;\nand (c) the display\nbeing used.\nHow do I create HD View content?\nMicrosoft\nImage\nComposite Editor (ICE) can now stitch your images and output\ndirectly to HD View or the new platform independent\nHD View SL.\u00a0\nYou can also use our\nPhotoshop plugin or\nthe hdmake\ncommand-line utility.\nG",
        "id": 2156,
        "title": "HD View"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/imagedeblurring/",
        "text": [
            "image",
            "deblurring",
            "image",
            "deblurring"
        ],
        "content": "Image Deblurring.  Image Deblurring",
        "id": 2157,
        "title": "Image Deblurring"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/imudeblurring/",
        "text": [
            "image",
            "deblurring",
            "using",
            "inertial",
            "measurement",
            "sensors",
            "abstract",
            "we",
            "present",
            "a",
            "deblurring",
            "algorithm",
            "that",
            "uses",
            "a",
            "hardware",
            "attachment",
            "coupled",
            "with",
            "a",
            "natural",
            "image",
            "prior",
            "to",
            "deblur",
            "images",
            "from",
            "consumer",
            "cameras",
            "our",
            "approach",
            "uses",
            "a",
            "combination",
            "of",
            "inexpensive",
            "gyroscopes",
            "and",
            "accelerometers",
            "in",
            "an",
            "energy",
            "optimization",
            "framework",
            "to",
            "estimate",
            "a",
            "blur",
            "function",
            "from",
            "the",
            "camera",
            "s",
            "acceleration",
            "and",
            "angular",
            "velocity",
            "during",
            "an",
            "exposure",
            "we",
            "solve",
            "for",
            "the",
            "camera",
            "motion",
            "at",
            "a",
            "high",
            "sampling",
            "rate",
            "during",
            "an",
            "exposure",
            "and",
            "infer",
            "the",
            "latent",
            "image",
            "using",
            "a",
            "joint",
            "optimization",
            "our",
            "meth"
        ],
        "content": "Image Deblurring using Inertial Measurement Sensors.  Abstract\nWe present a deblurring algorithm that uses a hardware attachment\ncoupled with a natural image prior to deblur images from consumer\ncameras. Our approach uses a combination of inexpensive gyroscopes\nand accelerometers in an energy optimization framework to\nestimate a blur function from the camera\u2019s acceleration and angular\nvelocity during an exposure. We solve for the camera motion at a\nhigh sampling rate during an exposure and infer the latent image\nusing a joint optimization. Our meth",
        "id": 2158,
        "title": "Image Deblurring using Inertial Measurement Sensors"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/ivt/",
        "text": [
            "interactive",
            "video",
            "tours",
            "we",
            "have",
            "developed",
            "a",
            "rapid",
            "method",
            "of",
            "capturing",
            "an",
            "indoor",
            "or",
            "outdoor",
            "space",
            "by",
            "using",
            "a",
            "portable",
            "multi",
            "camera",
            "rig",
            "we",
            "designed",
            "a",
            "viewer",
            "which",
            "gives",
            "a",
            "user",
            "the",
            "experience",
            "of",
            "interactively",
            "navigating",
            "through",
            "a",
            "photorealistic",
            "environment",
            "with",
            "the",
            "ability",
            "to",
            "move",
            "forward",
            "or",
            "backward",
            "and",
            "look",
            "around",
            "in",
            "any",
            "direction",
            "additionally",
            "we",
            "can",
            "augment",
            "this",
            "experience",
            "by",
            "adding",
            "extra",
            "multimedia",
            "content",
            "such",
            "as",
            "spatialized",
            "audio",
            "photographs",
            "and",
            "video",
            "textures",
            "to",
            "this",
            "basic",
            "experience",
            "we",
            "added",
            "high",
            "dynamic",
            "rang"
        ],
        "content": "Interactive Video Tours.  We have developed a rapid method of capturing an indoor or outdoor space by\nusing a portable multi-camera rig. We designed a viewer which gives a user the\nexperience of interactively navigating through a photorealistic environment,\nwith the ability to move forward or backward and look around in any direction.\nAdditionally we can augment this experience by adding extra multimedia content\nsuch as spatialized audio, photographs and video textures. To this basic\nexperience we added high dynamic rang",
        "id": 2159,
        "title": "Interactive Video Tours"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/phototours/",
        "text": [
            "photo",
            "tourism",
            "exploring",
            "photo",
            "collections",
            "in",
            "d",
            "photo",
            "tourism",
            "is",
            "a",
            "system",
            "for",
            "browsing",
            "large",
            "collections",
            "of",
            "photographs",
            "in",
            "d",
            "our",
            "approach",
            "takes",
            "as",
            "input",
            "large",
            "collections",
            "of",
            "images",
            "from",
            "either",
            "personal",
            "photo",
            "collections",
            "or",
            "internet",
            "photo",
            "sharing",
            "sites",
            "and",
            "automatically",
            "computes",
            "each",
            "photo",
            "s",
            "viewpoint",
            "and",
            "a",
            "sparse",
            "d",
            "model",
            "of",
            "the",
            "scene",
            "our",
            "photo",
            "explorer",
            "interface",
            "enables",
            "the",
            "viewer",
            "to",
            "interactively",
            "move",
            "about",
            "the",
            "d",
            "space",
            "by",
            "seamlessly",
            "transitioning",
            "between",
            "photographs",
            "based",
            "on",
            "user",
            "control"
        ],
        "content": "Photo Tourism: Exploring Photo Collections in 3D.  Photo Tourism is a system for browsing large collections of\nphotographs in 3D. Our approach takes as input large collections of\nimages from either personal photo collections or Internet photo sharing\nsites, and automatically computes each photo's viewpoint and a sparse 3D\nmodel of the scene. Our photo explorer interface enables the viewer to\ninteractively move about the 3D space by seamlessly transitioning\nbetween photographs, based on user control.",
        "id": 2160,
        "title": "Photo Tourism: Exploring Photo Collections in 3D"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/stitching/",
        "text": [
            "panoramic",
            "stitching",
            "stitching",
            "images",
            "to",
            "create",
            "panoramic",
            "photos",
            "is",
            "a",
            "very",
            "popular",
            "application",
            "but",
            "existing",
            "software",
            "packages",
            "still",
            "fall",
            "short",
            "of",
            "what",
            "users",
            "want",
            "applications",
            "that",
            "attempt",
            "to",
            "automatically",
            "stitch",
            "have",
            "a",
            "high",
            "rate",
            "of",
            "failure",
            "whereas",
            "those",
            "that",
            "yield",
            "the",
            "best",
            "results",
            "require",
            "a",
            "lot",
            "of",
            "user",
            "input",
            "we",
            "have",
            "developed",
            "a",
            "new",
            "tool",
            "that",
            "automatically",
            "stitches",
            "images",
            "and",
            "videos",
            "while",
            "producing",
            "the",
            "results",
            "that",
            "traditionally",
            "required",
            "a",
            "lot",
            "of",
            "hand",
            "authoring",
            "the",
            "user",
            "simply",
            "selects",
            "a",
            "group",
            "of",
            "images",
            "from",
            "with"
        ],
        "content": "Panoramic Stitching.  Stitching images to create panoramic photos is a very popular application,\nbut existing software packages still fall short of what users want. Applications\nthat attempt to automatically stitch have a high rate of failure, whereas those\nthat yield the best results require a lot of user input. We have developed a new\ntool that automatically stitches images and videos while producing the results\nthat traditionally required a lot of hand authoring. The user simply selects a\ngroup of images from with",
        "id": 2161,
        "title": "Panoramic Stitching"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/videotexture/",
        "text": [
            "video",
            "textures",
            "our",
            "video",
            "texture",
            "work",
            "involves",
            "the",
            "analysis",
            "of",
            "video",
            "to",
            "extract",
            "its",
            "stochastic",
            "structure",
            "and",
            "the",
            "subsequent",
            "synthesis",
            "of",
            "new",
            "frames",
            "based",
            "on",
            "this",
            "analysis",
            "we",
            "can",
            "capture",
            "facial",
            "expressions",
            "a",
            "candle",
            "flame",
            "or",
            "a",
            "waterfall",
            "and",
            "identify",
            "the",
            "repeating",
            "sections",
            "we",
            "then",
            "play",
            "back",
            "this",
            "video",
            "using",
            "random",
            "choices",
            "to",
            "give",
            "a",
            "sense",
            "of",
            "life",
            "that",
            "a",
            "static",
            "image",
            "or",
            "simple",
            "repeating",
            "video",
            "loop",
            "cannot",
            "provide",
            "this",
            "allows",
            "us",
            "to",
            "create",
            "lively",
            "video",
            "portraits",
            "with",
            "a",
            "similar",
            "look",
            "to",
            "those",
            "in",
            "harry",
            "potter"
        ],
        "content": "Video Textures.  Our video texture work involves the analysis of video to extract its\nstochastic structure and the subsequent synthesis of new frames based on this\nanalysis. We can capture facial expressions, a candle\nflame, or a waterfall and identify the repeating sections. We then play back\nthis video using random choices to give a sense of life that a static image or\nsimple repeating video loop cannot provide. This allows us to create lively video portraits with a similar look to those in \"Harry\nPotter.\"",
        "id": 2162,
        "title": "Video Textures"
    },
    {
        "url": "http://research.microsoft.com/en-us/um/redmond/groups/ivm/vvv/",
        "text": [
            "virtual",
            "viewpoint",
            "video",
            "video",
            "today",
            "is",
            "passive",
            "and",
            "two",
            "dimensional",
            "with",
            "dvd",
            "technology",
            "users",
            "have",
            "some",
            "limited",
            "control",
            "over",
            "how",
            "video",
            "is",
            "shown",
            "however",
            "the",
            "viewing",
            "experience",
            "can",
            "be",
            "made",
            "much",
            "more",
            "compelling",
            "if",
            "the",
            "user",
            "has",
            "the",
            "option",
            "of",
            "changing",
            "the",
            "viewpoint",
            "at",
            "any",
            "time",
            "providing",
            "a",
            "truly",
            "d",
            "experience",
            "our",
            "demo",
            "is",
            "a",
            "step",
            "in",
            "this",
            "direction",
            "it",
            "allows",
            "the",
            "user",
            "to",
            "seamlessly",
            "change",
            "the",
            "viewpoint",
            "while",
            "the",
            "video",
            "is",
            "playing",
            "the",
            "user",
            "can",
            "also",
            "freeze",
            "time",
            "while",
            "changing",
            "the",
            "viewpoint",
            "a",
            "la",
            "the",
            "matrix",
            "as",
            "a",
            "result",
            "no"
        ],
        "content": "Virtual Viewpoint Video.  Video today is passive and two-dimensional. With DVD technology, users have\nsome limited control over how video is shown. However, the viewing experience\ncan be made much more compelling if the user has the option of changing the\nviewpoint at any time, providing a truly 3D experience. Our demo is a step in\nthis direction; it allows the user to seamlessly change the viewpoint while the\nvideo is playing. The user can also freeze time while changing the viewpoint, a\nla \"The Matrix\". As a result, no",
        "id": 2163,
        "title": "Virtual Viewpoint Video"
    }
]